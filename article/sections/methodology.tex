\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../images/}}}

\begin{document}

\section{Materials and Methods}

This study relies on two large-scale datasets of C functions paired with x86\_64 assembly code: \textbf{ExeBench} and \textbf{The Stack}. These datasets serve as the foundation for training and evaluating data-driven decompilation models. This section details the data acquisition process, filtering strategies, structure, and known limitations.

\subsection{Dataset Overview}

We employ two complementary datasets:

\begin{itemize}
    \item \textbf{ExeBench}: A curated benchmark of executable C functions compiled at multiple optimization levels, designed for machine learning applications in compilation and decompilation \cite{armengol-estape_exebench_2022}.
    \item \textbf{The Stack}: A large-scale, permissively licensed source code repository that includes real-world C programs. While not originally intended for decompilation tasks, we compile and extract assembly representations from this dataset following a controlled pipeline \cite{kocetkov_stack_2022}.
\end{itemize}

\subsection{Data Collection and Preprocessing}

\subsubsection{ExeBench}

We process the \texttt{.jsonl.zst} files for each split (\texttt{train}, \texttt{validation}, and \texttt{test}) using \texttt{zstandard} decompression. From each JSONL entry, we extract the C source function from the \texttt{func\_def} field and the corresponding assembly from the \texttt{asm} field.

Assembly outputs include multiple compiler targets. We retain only those compiled with GCC for the x86 architecture (e.g., entries labeled \texttt{gcc\_O0}, \texttt{gcc\_Os}, \texttt{gcc\_O3}), discarding all others. This decision ensures uniformity in instruction set architecture (ISA) and aligns with common practices in decompilation research \cite{cao_boosting_2022}.

Examples are included only if they contain valid assembly code for at least one of the selected optimization levels. Most commonly, \texttt{-O0} is present, with \texttt{-Os} and \texttt{-O3} available in a substantial subset of the corpus.

\subsubsection{The Stack}

To complement ExeBench with more realistic code, we extract a subset of C source files from The Stack. These were compiled using \texttt{GCC 10.2.1} on \texttt{Debian 10 (buster)}, targeting the \texttt{x86} ISA. Compilation was performed for optimization levels \texttt{-O0}, \texttt{-Os}, and \texttt{-O3}.

Files were discarded if they failed to compile, produced empty output, or required external dependencies. Successfully compiled examples were parsed to extract assembly code and paired with the original C function. Only files with at least one valid optimization level were retained.

\subsection{Dataset Structure}

Each valid example is stored as a JSON object with the following structure:

\begin{itemize}
    \item \texttt{c}: the original C function code.
    \item \texttt{asm}: a dictionary mapping optimization levels (e.g., \texttt{O0}, \texttt{Os}, \texttt{O3}) to the corresponding x86 assembly code.
\end{itemize}

Examples are organized into directories according to their respective splits: \texttt{train/}, \texttt{valid/}, and \texttt{test/}. Assembly outputs are normalized to remove formatting artifacts, improving downstream processing without altering semantics.

\subsection{Dataset Composition}

The final dataset composition is summarized below, distinguishing between the ExeBench and The Stack corpora. Each example is considered valid if it contains a successfully compiled C function paired with its corresponding x86 assembly representation for at least one of the selected optimization levels (\texttt{-O0}, \texttt{-Os}, \texttt{-O3}).

\begin{itemize}
    \item \textbf{ExeBench}:
    \begin{itemize}
        \item Approx.\ 20,950 total examples in the full dataset.
        \item All examples contain \texttt{O0}; around 70\% also include \texttt{Os} and/or \texttt{O3}.
    \end{itemize}
    \item \textbf{The Stack}:
    \begin{itemize}
        \item Approx.\ 120,000 compiled examples considered initially.
        \item A filtered subset of 348 valid examples was selected for evaluation purposes.
        \item Over 85\% of retained examples include multiple optimization levels.
    \end{itemize}
\end{itemize}

Tables~\ref{tab:stack_dist} and~\ref{tab:exebench_dist} provide a breakdown of optimization levels and examples across splits for both datasets.

\vspace{1em}

\begin{table}[H]
\centering
\caption{Distribution of processed examples from The Stack by split and optimization level}
\label{tab:stack_dist}
\begin{tabular}{lccc}
\toprule
\textbf{Optimization Level} & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
\midrule
O0 & 93 & 12 & 11 \\
Os & 93 & 12 & 11 \\
O3 & 93 & 11 & 12 \\
\midrule
\textbf{Total} & \textbf{279 (80.17\%)} & \textbf{35 (10.06\%)} & \textbf{34 (9.77\%)} \\
\bottomrule
\end{tabular}
\end{table}

\vspace{1em}

\begin{table}[H]
\centering
\caption{Distribution of processed examples from ExeBench by split and optimization level}
\label{tab:exebench_dist}
\begin{tabular}{lccc}
\toprule
\textbf{Optimization Level} & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
\midrule
O0 & 5582 & 698 & 698 \\
Os & 5588 & 699 & 698 \\
O3 & 5587 & 699 & 699 \\
\midrule
\textbf{Total} & \textbf{16757 (80.00\%)} & \textbf{2096 (10.00\%)} & \textbf{2095 (10.00\%)} \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Limitations}

Despite the careful design and preprocessing of the datasets, several practical limitations must be acknowledged.

\textbf{Storage space} was a significant constraint. The total size of the dataset exceeded 60~GB, which can be challenging to manage in constrained computing environments or when reproducing results. The final dataset was deliberately capped to ensure accessibility and feasibility for training and evaluation.

Additionally, the \textbf{data preparation pipeline} required substantial \textbf{processing time}. Larger-scale processing---such as compiling all C files available in The Stack---was deemed infeasible within our compute budget, leading us to restrict the final corpus.

A further limitation involves the \textbf{compilability} of real-world source code. A significant number of C files from The Stack could not be compiled due to syntax errors, reliance on platform-specific headers, unresolved macros, or missing dependencies. These cases were automatically filtered out. Although this process ensured that all included samples were syntactically and semantically valid, it introduces a selection bias that favors simpler or more portable code.

Lastly, \textbf{example length} posed a constraint from a model architecture perspective. Transformer-based language models operate with fixed-length input windows. In our case, the DistilGPT variant used during experimentation is limited to a context window of approximately 1024 tokens. Some valid examples---especially those containing large functions or multiple optimization levels---exceeded this limit and could not be processed end-to-end. Although we considered filtering out these longer samples, doing so would bias the dataset toward short and trivial functions, reducing its representativeness. As such, we retained these examples in the dataset, with the understanding that future work may require truncation, segmentation, or hierarchical modeling strategies to accommodate them.

\end{document}
