# Tools
from .gen_splits import gen_splits
from .gen_examples import gen_examples

# Argument parsing
import argparse
from sys import argv, exit, stderr

if __name__ == "__main__":
    # Keep track of argument parsing
    parser = argparse.ArgumentParser(
        description='Process source C files and x86 assemblies from ExeBench and The Stack into a dataset')
    
    # Register subcommands
    sub_parsers = parser.add_subparsers(dest="selected_command", required=True,
        help='Either generate examples or splits for the dataset')
    
    # - Generate examples
    examples_parser = sub_parsers.add_parser("examples", 
        help="Generate C and x86 pairs as examples on disk")
    
    # - - Register arguments
    examples_parser.add_argument('output_dir', type=str, 
        help='Path to output directory of dataset')
    examples_parser.add_argument('exebench_dir', type=str, 
        help='Path to input directory of compressed (*.zst) dataset files (*.jsonl) with ExeBench splits')
    examples_parser.add_argument('stack_token_file', type=str, 
        help='Path to file containing an HuggingFace API token (on the first line) with read access to The Stack\'s dataset')
    examples_parser.add_argument('max_exebench_size', type=int, 
        help='Maximum size (in units) of processed content for examples in ExeBench')
    examples_parser.add_argument('max_stack_size', type=int, 
        help='Maximum size (in units) of processed content for examples in The Stack')
    examples_parser.add_argument('unit', type=str, choices=["KB", "MB", "GB"], 
        help='Unit of size to use when limiting processing output files total size (bytes)')

    # - Generate splits from examples
    splits_parser = sub_parsers.add_parser("splits", 
        help="Generate train, test and validation splits from dataset generated by 'examples' command")
    
    # -- Register arguments
    # - - Register arguments
    splits_parser.add_argument('root_dir', type=str, 
        help='Path to root directory of dataset')
    splits_parser.add_argument('csv_mappings', type=str, 
        help='Path under root directory to mappings between C and x86 files generated for dataset')
    splits_parser.add_argument('seed', type=int, default=0,
        help='Seed used for randomly splitting the data')
    splits_parser.add_argument('p_train', type=float,
        help='Percent of examples allocated to the train split')
    splits_parser.add_argument('p_val', type=float,
        help='Percent of examples allocated to the validation split')

    # If no arguments are passed, print the usage
    if (len(argv) == 0):
        parser.parse_args(["-h"])
        exit(0)
    
    # Otherwise, parse the commands and run accordingly
    parameters = vars(parser.parse_args()) # Collect the parameters
    command = parameters["selected_command"] # Collect the command
    del parameters["selected_command"] # Keep only relevant parameters

    if command == "examples":
        print("Generating examples in dataset...")
        gen_examples(**parameters)
    elif command == "splits":
        print("Generating split mappings for dataset...")
        gen_splits(**parameters)
    else:
        print(f"Unrecognized subcommand '{command}'", file=stderr)
        exit(-1)

    print("Done!")
